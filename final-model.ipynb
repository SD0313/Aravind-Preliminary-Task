{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras import layers as L\n\n\nimport numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = '../input/origalist/Cropped Images/Cropped Images'","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_datagen = ImageDataGenerator(rescale=1/255.,\n                                zoom_range=0.2,\n                                rotation_range=40,\n                                width_shift_range=0.3,\n                                height_shift_range=0.3,\n                                brightness_range=[0.2, 1.0],\n                                vertical_flip=True,\n                                horizontal_flip=True,\n                                validation_split=0.2)\n\ntrain_generator = img_datagen.flow_from_directory(directory,\n                                                 target_size=(224, 224),\n                                                 class_mode='binary',\n                                                 subset='training',\n                                                  batch_size=16,\n                                                 shuffle=True)\n\nvalid_generator = img_datagen.flow_from_directory(directory,\n                                                 target_size=(224, 224),\n                                                 class_mode='binary',\n                                                 subset='validation',\n                                                  batch_size=1,\n                                                 shuffle=True)","execution_count":3,"outputs":[{"output_type":"stream","text":"Found 1818 images belonging to 2 classes.\nFound 454 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential()\n\nmodel.add(InceptionV3(include_top=False, input_shape=(224, 224, 3), weights='imagenet'))\nmodel.add(L.GlobalAveragePooling2D())\nmodel.add(L.Dense(128, activation='relu'))\nmodel.add(L.Dropout(0.3))\nmodel.add(L.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=keras.optimizers.SGD(1e-4, 0.9), loss='binary_crossentropy',\n              metrics=['accuracy', keras.metrics.AUC(name='auc')])","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87916544/87910968 [==============================] - 3s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":5,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               262272    \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 22,065,185\nTrainable params: 22,030,753\nNon-trainable params: 34,432\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"{'Glaucoma': 0, 'Healthy': 1}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nlabels = train_generator.labels\nweights = compute_class_weight('balanced', np.unique(labels), labels)","execution_count":7,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = {0: weights[0],\n               1: weights[1]}","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy')>0.7):\n            print(\"\\nReached 70% accuracy so cancelling training!\")\n            self.model.stop_training = True\n        if (logs.get('val_auc') > 0.69):\n            print(\"\\nReached 70% AUC score so cancelling training!\")\n            self.model.stop_training = True","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = train_generator.n//train_generator.batch_size\nVALIDATION_STEPS = valid_generator.n//valid_generator.batch_size\nEPOCHS = 100\n\n\nhistory = model.fit(train_generator, steps_per_epoch=STEPS_PER_EPOCH,\n                   validation_data=valid_generator, validation_steps=VALIDATION_STEPS, \n                    class_weight=class_weight, callbacks=[myCallback()], epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('final_model.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}