{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_9cat(y_true, y_pred, smooth=1e-7):\n",
    "    '''\n",
    "    Dice coefficient for 3 categories. Ignores background pixel label 0\n",
    "    Pass to model as metric during compile statement\n",
    "    '''\n",
    "    y_true_f = K.flatten(K.one_hot(K.cast(y_true, 'int32'), num_classes=3)[...,1:])\n",
    "    y_pred_f = K.flatten(y_pred[...,1:])\n",
    "    intersect = K.sum(y_true_f * y_pred_f, axis=-1)\n",
    "    denom = K.sum(y_true_f + y_pred_f, axis=-1)\n",
    "    return K.mean((2. * intersect / (denom + smooth)))\n",
    "\n",
    "def dice_coef_9cat_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Dice loss to minimize. Pass to model as loss during compile statement\n",
    "    '''\n",
    "    return 1 - dice_coef_9cat(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = dice_coef_9cat_loss\n",
    "segmentation_model = keras.models.load_model('C:\\Luna_CS\\Aravind\\working_model.h5', \n",
    "                                   custom_objects={ loss.__name__: loss })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nerves(image):\n",
    "    img = array_to_img(image)\n",
    "    \n",
    "    img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
    "    # convert image to grayScale\n",
    "    grayScale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "   \n",
    "    # kernel for morphologyEx\n",
    "    kernel = cv2.getStructuringElement(1,(17,17))\n",
    "   \n",
    "    # apply MORPH_BLACKHAT to grayScale image\n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "  \n",
    "    # apply thresholding to blackhat\n",
    "    _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    # inpaint with original image and threshold image\n",
    "    final_image = cv2.inpaint(img,threshold,1,cv2.INPAINT_TELEA)\n",
    "    final_image = cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return final_image.astype(np.float64)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image(file, model):\n",
    "    test_img = load_img(file, target_size=(512, 512))\n",
    "    test_img_original = load_img(file)\n",
    "    full_arr = np.array(test_img_original)/255.0\n",
    "    x_true = full_arr.shape[0]\n",
    "    y_true = full_arr.shape[1]\n",
    "    test_arr = img_to_array(test_img)/255.0\n",
    "    \n",
    "    test_arr_preprocessed = remove_nerves(test_arr)\n",
    "\n",
    "    pred = model.predict(test_arr_preprocessed.reshape(1, 512, 512, 3))\n",
    "    single_pred = pred[0]\n",
    "    mask_img = array_to_img(single_pred)\n",
    "    mask_img = mask_img.resize((y_true, x_true))\n",
    "    mask_arr = np.array(mask_img)/255.0\n",
    "    my_mask = np.zeros((x_true, y_true))\n",
    "    marked = []\n",
    "    inner = []\n",
    "    for i in range(x_true):\n",
    "        for j in range(y_true):\n",
    "            if np.argmax(mask_arr[i][j]) != 0:\n",
    "                marked.append([i, j])\n",
    "                \n",
    "    avgi = []\n",
    "    avgj = []\n",
    "    for lis in marked:\n",
    "        first = lis[0]\n",
    "        sec = lis[1]\n",
    "        avgi.append(first)\n",
    "        avgj.append(sec)\n",
    "        \n",
    "\n",
    "        \n",
    "    avgi = sum(avgi)//len(avgi)\n",
    "    avgj = sum(avgj)//len(avgj)\n",
    "    \n",
    "    middle  = (avgi, avgj)\n",
    "    K = int((300.0/6291456.0)*float(x_true*y_true))\n",
    "    top = middle[1] - K\n",
    "    bottom = middle[1] + K\n",
    "    left = middle[0] - K\n",
    "    right = middle[0] + K\n",
    "    \n",
    "    cropped = test_img_original.crop(((top, left, bottom, right)))\n",
    "\n",
    "    return np.array(cropped)/255.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = keras.models.load_model('C:\\Luna_CS\\Aravind\\\\final_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method ```get_diagnosis``` takes 2 input parameters. The first one is the path to the image, and the next is a boolean value representing whether the image needs to be cropped or not. If cropping is necessary, the segmentation model will be used. If not, then only the classification model will be required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnosis(file, full_image=True):\n",
    "    '''\n",
    "    Set full_image=True if image is not pre-cropped\n",
    "    Else set full_image=False\n",
    "    '''\n",
    "    \n",
    "    if full_image:\n",
    "        img = get_cropped_image(file, segmentation_model)\n",
    "        img = array_to_img(img)\n",
    "        img = img.resize((224, 224))\n",
    "        img = np.array(img)/255.0\n",
    "    else:\n",
    "        img = np.array(load_img(file, target_size=(224, 224)))/255.0\n",
    "        \n",
    "        \n",
    "    pred = classification_model.predict(img.reshape(1, 224, 224, 3))\n",
    "\n",
    "    if pred[0] > 0.5:\n",
    "        print('Healthy')\n",
    "        \n",
    "    else:\n",
    "        print('Risk of Glaucoma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are two test images. The first is already cropped and the second one isn't. Cropping the image takes time, so the diagnosis will not be as fast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk of Glaucoma\n"
     ]
    }
   ],
   "source": [
    "get_diagnosis('C:\\Luna_CS\\Aravind\\Database\\Images\\Im530_g_ACRIMA.jpg', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "get_diagnosis('C:\\Luna_CS\\Aravind\\ORIGA\\Images\\\\002.jpg', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
